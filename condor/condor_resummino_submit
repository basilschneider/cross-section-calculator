#!/usr/bin/env bash

# Submit jobs to HTCondor to calculate different cross sections

# Don't expand unset parameters
set -u

# Disable pathname expansions, otherwise the user can pass "*" as an option and
# wreak havoc
set -f

# Default values for user options
dryrun=false
slha=hino.in
com=13
p="1000023 1000024"
mass="100 200 300"
mus="1.0"
pdf_w=central

# Accepted values
p_good=(1000022 1000023 1000024 -1000024 1000015 -1000015)
pdf_good=(all central)

# Error handling
err=false

# Names
name_submission_script=condor_resummino_submission

# External tarballs
resummino=resummino-2.0.1-looptools.tar.bz2
gsl=gsl-1.13.tar.gz

usage(){
    echo "Submit jobs to calculate cross sections with Resummino."
    echo "This will generate one job per mass point times different"
    echo "scale factors times different PDF sets."
    echo
    echo "Usage: $(basename $0) [options]"
    echo "where [options] can be"
    echo "  -h               Show this help"
    echo "  -d               Dryrun, don't submit any jobs"
    echo "  -s slha          SLHA to be used (default: ${slha})"
    echo "  -e n             Center of mass energy in TeV (default: ${com})"
    echo "  -p \"m n\"         PDGIDs of particles (default: ${p})"
    echo "  -m \"x y z\"       List of mass points (default: ${mass})"
    echo "  -u \"x y z\"       List of renormalization and factorization"
    echo "                   scale factors (default: ${mus})"
    echo "  -x (all/central) Set PDF sets (default: ${pdf_w})"
}

# Check if array contains element "${1}"
contains_element () {
    local match="${1}"
    local element
    shift
    for element; do
        [ "${element}" == "${match}" ] && return 0
    done
    return 1
}

makeTarball(){
    # Create new tarball
    echo -n "Create tarball ${name_tarball} with input files... "
    tar czf "${name_tarball}" resummino.in hino.in wino.in
    if [ $? -ne 0 ]; then
        echo "Exit"
        exit 1
    fi
    echo "Done."
}

prepare(){
    echo -n "Set center of mass energy to ${com} TeV in Resummino config... "
    sed -i "/^center_of_mass_energy/ccenter_of_mass_energy = ${com}000" \
        resummino.in
    echo "Done."

    echo -n "Set input SLHA file to ${slha}... "
    sed -i -e "/^slha/cslha = ${slha}" resummino.in
    echo "Done."

    echo "Particles set to ${p1} and ${p2}."
    echo "Masses set to ${mass}."
    echo "Renormalization and factorization scale factors set to ${mus}."
    echo "PDF sets set to ${pdf_w}."
}

submit(){
    echo -n "Set up submission script... "
    rm -f "${name_submission_script}"

# Fill default values to submission script
cat << EOF >> "${name_submission_script}"
universe = vanilla
Executable = condor_resummino
Requirements = OpSys == "LINUX" && (Arch != "DUMMY" )
request_disk = 400000
request_memory = 1000
Transfer_Input_Files = condor_resummino, ${name_tarball}, ${resummino}, ${gsl}
notification = Never
Should_Transfer_Files = YES
WhenToTransferOutput = ON_EXIT
Transfer_Output_Files = condor_output_dummy
x509userproxy = \$ENV(X509_USER_PROXY)
Output = logs/condor_\$(Cluster).\$(Process).stdout
Error = logs/condor_\$(Cluster).\$(Process).stderr
Log = logs/condor_\$(Cluster).\$(Process).condor
EOF

    # For every mass point, create a job
    for m in ${mass}; do
        # Zero pad masses, so they are ordered correctly when harvesting
        m=$(printf "%04d" "${m}")
        # For every scale factor, create a job
        for mu in ${mus}; do
            # For every pdf set, create a job
            for pdf in ${pdfs}; do
                echo "Arguments = ${slha} ${com} ${p1} ${p2} ${m} ${mu} ${pdf} \$(Cluster) \$(Process)" >> \
                    "${name_submission_script}"
                echo "Queue 1" >> "${name_submission_script}"
            done
        done
    done
    echo "Done."

    # Submit jobs
    if [ ! "${dryrun}" == true ]; then
        condor_submit "${name_submission_script}"
    fi
}

parseOptions(){

    OPT=$(getopt \
        --options hde:p:s:m:u:x: \
        --name "$0" \
        -- "$@"
    )

    if [ $? -ne 0 ]; then
        err=true
    fi

    eval set -- "${OPT}"

    while true; do
        case "${1}" in
            -h) usage; exit 0;;
            -d) dryrun=true; shift;;
            -s) slha="${2}"; shift 2;;
            -e) com="${2}"; shift 2;;
            -p) p="${2}"; shift 2;;
            -m) mass="${2}"; shift 2;;
            -u) mus="${2}"; shift 2;;
            -x) pdf_w="${2}"; shift 2;;
            --) shift; break;;
        esac
    done

    if [ "${err}" = true ]; then
        usage
        exit 1
    fi

    # Split p into p1 and p2
    p1="${p% *}"
    p2="${p#* }"
    unset p

    # Make sure particles are accepted
    if ! contains_element "${p1}" "${p_good[@]}" || \
       ! contains_element "${p2}" "${p_good[@]}"; then
        echo "Particle ${p1} or ${p2} is not accepted."
        echo "Exit."
        exit 2
    fi

    # Make sure PDF sets are accepted
    if ! contains_element "${pdf_w}" "${pdf_good[@]}"; then
        echo "PDF set ${pdf_w} is not accepted."
        echo "Exit."
        exit 2
    fi

    # Make sure abs(p1) <= abs(p2)
    if [ "${p1#-}" -gt "${p2#-}" ]; then
        p1temp="${p1}"
        p1="${p2}"
        p2="${p1temp}"
        unset p1temp
    fi

    # Set numbers of PDF sets
    if [ "${pdf_w}" == all ]; then
        pdfs=$(echo {0..100})
    else
        pdfs=0
    fi

    # Set the unique name of the tarball
    # This is needed in order to quickly send different jobs, without
    # overwriting the respective tarballs
    name_tarball=tarball_resummino_$(date +%s%3N).tar.gz

    prepare
    makeTarball
    submit
}

parseOptions "$@"
